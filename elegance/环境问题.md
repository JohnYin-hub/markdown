

# conda环境

## 创建虚拟环境

```bash
#指定 python 版本号
conda create -n py39 python=3.9
#复制其他环境
conda create -n traget_env_name --clone source_env_name
#clone 可为环境路径
conda create -n traget_env_name --clone ~/path
#是否自动activate
conda config --set auto_activate_base false
#删除环境
conda remove --name xxxx  --all #彻底删除旧环境
```

## 将虚拟环境添加到jupyter kernel

```bash
#添加到kernel
python -m ipykernel install --name data
#ipython 方法添加
ipython kernel install --user --name your_name
#查看jupyter下面有多少个kernels
jupyter kernelspec list
#删除指定的 kernel（以data环境为例
jupyter kernelspec remove data
```

## 		pip切换镜像源

```bash
/Usr/home/.pip/pip.conf
[global]
index-url = http://mirrors.aliyun.com/pypi/simple/
[install]
trusted-host=mirrors.aliyun.com
#----------------------------------------------------
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --set show_channel_urls yes
#-----------------------------------------------------
conda config --show-sources
#conda 再进行安装
conda install -n "yourname" ipykernel --update-deps --force-reinstall
# pip几个镜像源
https://pypi.tuna.tsinghua.edu.cn/simple
https://mirrors.aliyun.com/pypi/simple/
https://pypi.douban.com/simple/
```

# GPU 环境

## tensorflow验证环境

##### **tensorflow代码**

```python
import tensorflow as tf
tf.test.is_gpu_available() #tf1版本验证gpu是否可用
# True or False
tf.test.is_built_with_gpu_support() #tf2 版本验证GPU是否可用
tf.config.list_physical_devices('GPU') #tf2 展示GPU情况
#[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
len(tf.config.experimental.list_physical_devices('GPU')) #GPU数量
```

##### Tf 使用gpu

```python

# 方式1. 直接在python文件最开始指定GPU
import os
# os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"  # 默认，不需要这句
os.environ["CUDA_VISIBLE_DEVICES"] = "0" # 选择ID为0的GPU
 
# 方式2. 通过ID选择GPU
def selectGpuById(id):
    os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
    os.environ["CUDA_VISIBLE_DEVICES"] = "{}".format(id)
 
## 方式3. session中指定GPU
with tf.Session() as ses:
    with tf.device("/gpu:1"):
        # 训练model的代码
## 字符说明：
##"/cpu:0"	The CPU of your machine

#限制大小
gpus = tf.config.experimental.list_physical_devices('GPU')  # 获取GPU列表
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)
    # 失效： tf.config.experimental.set_per_process_memory_fraction(0.25)
    # 第一个参数为原则哪块GPU，只有一块则是gpu[0],后面的memory_limt是限制的显存大小，单位为M
    tf.config.experimental.set_virtual_device_configuration(gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*12)]) 
```

## Pytorch验证环境

##### **pytorch代码**

```python
torch.cuda.is_available()
torch.cuda.device_count()
 
torch.cuda.current_device() #当前设备名称，目前硬件只有一个gpu
torch.cuda.get_device_name(0) #第一块gpu内容
```

## GPU监控

##### Nvidia 自带工具

```bash
nvidia-smi
Wed Apr 27 16:30:55 2022
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  Off  | 00000000:65:00.0 Off |                    0 |
| N/A   33C    P0    36W / 250W |      0MiB / 40536MiB |     31%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
 
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
 
Fan：显示风扇转速，数值在0到100%之间，是计算机的期望转速，如果计算机不是通过风扇冷却或者风扇坏了，显示出来就是N/A；
Temp：显卡内部的温度，单位是摄氏度；
Perf：表征性能状态，从P0到P12，P0表示最大性能，P12表示状态最小性能；
Pwr：能耗表示；
Bus-Id：涉及GPU总线的相关信息；
Disp.A：是Display Active的意思，表示GPU的显示是否初始化；
Memory Usage：显存的使用率；
Volatile GPU-Util：浮动的GPU利用率；
Compute M：计算模式；
 
watch -n 5 nvidia-smi #隔5秒显示一次
```

## **gpustat**

安装 pip install gpusta

```bash
gpustat -i
watch --color -n1 gpustat -cpu
```

## GPU 内存释放

会出现候程序已经结束了，`nvidia-smi`也看到没有程序了，但是`GPU`的内存并没有释放的情况。这是由于内部伪多线程读取数据造成的。

彻底释放gpu内存代码步骤如下

```bash
fuser -v /dev/nvidia*  #获取占用显存的程序
 
fuser -v /dev/nvidia*|awk -F " " '{print $0}' >/tmp/pid.file #把他们的pid重定向到一个文件
 
while read pid ; do kill -9 $pid; done </tmp/pid.file  #循环强杀
 
# 或者不用重定向到文件，直接杀
# 杀自己占用GPU的程序
fuser -v /dev/nvidia*|awk -F " " '{print $0}' | xargs kill -s 9
# 通杀
sudo fuser -v /dev/nvidia*|awk -F " " '{print $0}' | xargs sudo kill -s 9
```